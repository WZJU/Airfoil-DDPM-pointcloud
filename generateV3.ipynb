{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7bf4d69",
   "metadata": {},
   "source": [
    "# This file is generation code of Airfoil_DDPM. Using pretrained model to generate airfoil.\n",
    "# Author: Zhe Wen\n",
    "# Date: 2025-5-22\n",
    "# Copyright (c) Zhejiang University. All rights reserved.\n",
    "# See LICENSE file in the project root for license information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa11ede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from Airfoil_DDPM_pointcloudV32 import Unet,Airfoil_DDPM_multitask\n",
    "\n",
    "\n",
    "import datetime\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e77c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gaussian_tensor(batch_size, dim, size):\n",
    "    tensor = torch.empty(batch_size, dim, size)\n",
    "    for i in range(batch_size):\n",
    "        for j in range(dim):\n",
    "            tensor[i, j] = torch.normal(mean=0.0, std=1.0, size=(size,))\n",
    "    return tensor\n",
    "\n",
    "def partial_load_state_dict(model, checkpoint):\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = checkpoint['models']\n",
    "    filtered_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and model_dict[k].shape == pretrained_dict[k].shape}\n",
    "    model_dict.update(filtered_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86dbdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "proj_path = os.path.join(os.getcwd(), 'log/pointcloud_diffusion/2025-06-20_16-11')\n",
    "\n",
    "# 将目标路径添加到 sys.path\n",
    "sys.path.append(str(proj_path))\n",
    "from argument_parser import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf79bfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数默认值: {'device': 'cuda', 'log_dir': None, 'model': 'pointcloud_diffusion', 'data_path': None, 'learning_rate': 0.0001, 'epochs': 100, 'train_split': 0.8, 'valid_split': 0.1, 'batch_size': 24, 'shuffle': True, 'num_workers': 2, 'time_step': 500}\n",
      "默认设备: cuda\n"
     ]
    }
   ],
   "source": [
    "# 获取 parser 对象但不执行 parse_args()\n",
    "def inspect_parser_defaults():\n",
    "    import argparse\n",
    "    # 临时创建一个新的 parser 实例\n",
    "    temp_parser = argparse.ArgumentParser()\n",
    "    # 添加和原 parser 相同的参数\n",
    "    temp_parser.add_argument('--device', type=str, default='cuda', help='')#\n",
    "    temp_parser.add_argument('--log_dir', type=str, default=None, help='')#\n",
    "    temp_parser.add_argument('--model', type=str, default='pointcloud_diffusion', help='')#\n",
    "    temp_parser.add_argument('--data_path', type=str, default=None, help='')#\n",
    "    temp_parser.add_argument('--learning_rate', default=0.0001, type=float, help='learning rate in training')#\n",
    "    temp_parser.add_argument('--epochs', default=100, type=int, help='learning rate in training')#\n",
    "    temp_parser.add_argument('--train_split', default=0.8, type=float, help='learning rate in training')#\n",
    "    temp_parser.add_argument('--valid_split', default=0.1, type=float, help='learning rate in training')#\n",
    "    temp_parser.add_argument('--batch_size', default=24, type=int, help='learning rate in training')#\n",
    "    temp_parser.add_argument('--shuffle', default=True, type=bool, help='learning rate in training')#\n",
    "    temp_parser.add_argument('--num_workers', default=2, type=int, help='learning rate in training')#\n",
    "    temp_parser.add_argument('--time_step', default=500, type=int, help='learning rate in training')#\n",
    "    # ... 添加其他参数（需与 argument_parser.py 中一致）\n",
    "    \n",
    "    # 提取所有参数的默认值\n",
    "    defaults = {action.dest: action.default \n",
    "               for action in temp_parser._actions \n",
    "               if action.dest != 'help'}\n",
    "    return defaults\n",
    "\n",
    "# 查看默认值\n",
    "defaults = inspect_parser_defaults()\n",
    "print(\"参数默认值:\", defaults)\n",
    "print(\"默认设备:\", defaults[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dae98148",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''DEVICE'''\n",
    "if defaults[\"device\"] == 'cuda' and torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    if defaults[\"device\"] == 'cuda':  # 用户想用 GPU 但不可用时警告\n",
    "        print(\"[Warning] CUDA not available. Falling back to CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f11b2589",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'd:\\\\generate_2\\\\Airfoil-DDPM-pointcloud\\\\log/pointcloud_diffusion/2025-06-19_14-38\\\\checkpoints/best_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m df_model\u001b[38;5;241m=\u001b[39mUnet(point_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, context_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, residual\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      2\u001b[0m weight_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(proj_path,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoints/best_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m df_model \u001b[38;5;241m=\u001b[39m partial_load_state_dict(df_model, checkpoint)\n\u001b[0;32m      5\u001b[0m generate_model \u001b[38;5;241m=\u001b[39m Airfoil_DDPM_multitask(df_model)\n",
      "File \u001b[1;32mc:\\Users\\WednZ\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\WednZ\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\WednZ\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'd:\\\\generate_2\\\\Airfoil-DDPM-pointcloud\\\\log/pointcloud_diffusion/2025-06-19_14-38\\\\checkpoints/best_model.pth'"
     ]
    }
   ],
   "source": [
    "df_model=Unet(point_dim=2, context_dim=6, residual=True).to(device)#\n",
    "weight_path = os.path.join(proj_path,'checkpoints/best_model.pth')\n",
    "checkpoint = torch.load(weight_path, map_location=torch.device(defaults[\"device\"]), weights_only=True)\n",
    "df_model = partial_load_state_dict(df_model, checkpoint)\n",
    "generate_model = Airfoil_DDPM_multitask(df_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf716705",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''给定初始化噪声点用于去噪,[B, dim, num]'''\n",
    "x = torch.normal(mean=0, std=1, size=(200,)).reshape(1,-1,2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d11a1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#context = torch.tensor([[1.75E-02,1.30E-01,3.03E-01,9.56E-01,7.92E-03,-9.15E-02],[2.94E-02,1.50E-01,3.64E-01,5.52E-01,6.55E-03,-1.12E-01],[1.03E-02,9.81E-02,3.03E-01,2.16E-01,5.30E-03,-1.70E-03]])\n",
    "context = torch.tensor([1.75E-02,1.30E-01,3.03E-01,9.56E-01,7.92E-03,-9.15E-02])\n",
    "context = context.view(-1,1,6).cuda()\n",
    "ret_points = generate_model(x=x, context=context, t_max=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afdc5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ret_points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165a87c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "points = ret_points.permute(0,2,1).squeeze(0).T.detach().cpu().numpy()   # shape [100, 2]\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(points[:, 0], points[:, 1], \n",
    "            c='blue', alpha=0.6, \n",
    "            edgecolors='w', s=50)\n",
    "\n",
    "plt.title(\"2D Points Visualization (100 points)\")\n",
    "plt.xlabel(\"X-axis\")\n",
    "plt.ylabel(\"Y-axis\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
